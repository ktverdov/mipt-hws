{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt_dates_tatoeba.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "kOD7y3WpcWFv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\">Organization Info</h1> \n",
        "\n",
        "* Дедлайн **DD MM 2018 23:59** для всех групп.\n",
        "* В качестве решения задания нужно прислать ноутбук с подробными комментариями (<span style='color:red'> без присланного решения результат контеста не будет засчитан </span>).\n",
        "* <span style='color:red'>Название команды в контесте должно соответствовать шаблону: НомерГруппы_Имя_Фамилия, например, 594_Ivan_Ivanov</span>."
      ]
    },
    {
      "metadata": {
        "id": "1CdwyD6NcWFx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Оформление дз**: \n",
        "- Присылайте выполненное задание на почту ``ml.course.mipt@gmail.com``\n",
        "- Укажите тему письма в следующем формате ``ML2018_fall_<номер_группы>_<фамилия>``, к примеру -- ``ML2018_fall_495_ivanov``\n",
        "- Выполненное дз сохраните в файл ``<фамилия>_<группа>_task<номер>.ipnb, к примеру`` -- ``ivanov_401_task7.ipnb``\n",
        "\n",
        "**Вопросы**:\n",
        "- Присылайте вопросы на почту ``ml.course.mipt@gmail.com``\n",
        "- Укажите тему письма в следующем формате ``ML2018_fall Question <Содержание вопроса>``\n",
        "\n",
        "\n",
        "--------\n",
        "- **PS1:** Используются автоматические фильтры, и просто не найдем ваше дз, если вы неаккуратно его подпишите.\n",
        "- **PS2:**  Просроченный дедлайн снижает максимальный вес задания по формуле, указнной на первом семинаре\n",
        "- **PS3:** Допустимы исправление кода предложенного кода ниже, если вы считаете"
      ]
    },
    {
      "metadata": {
        "id": "WoyWxPmfcWFy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\">Checking Questions</h1> \n",
        "\n",
        "**Вопрос 1**: Чем LSTM лучше/хуже чем обычная RNN?\n",
        "\n",
        "*Ответ:* \n",
        "\n",
        "Плюсы: LSTM решает проблемы взрывающихся / затухающих градиентов, за счет этого нейронная сеть может дольше помнить о зависимостях во входящих последовательностях. \n",
        "\n",
        "Минусы: Увеличивается сложность математической модели при обновлении весов / пересчете градиентов. Увеличивается сложность нейронной сети, т.к. растет количество весов. \n",
        "\n",
        "**Вопрос 2**:  Выпишите производную $\\frac{d c_{n+1}}{d c_{k}}$ для LSTM http://colah.github.io/posts/2015-08-Understanding-LSTMs/, объясните формулу, когда производная затухает, когда взрывается?\n",
        "\n",
        "<Ответ>\n",
        "\n",
        "**Вопрос 3**: Зачем нужен TBPTT почему BPTT плох?\n",
        "\n",
        "<Ответ>\n",
        "\n",
        "\n",
        "**Вопрос 4**: Как комбинировать рекуррентные и сверточные сети, а главное зачем? Приведите несколько примеров реальных задач.\n",
        "\n",
        "<Ответ>\n",
        "\n",
        "**Вопрос 5**: Можно ли использовать сверточные сети для классификации текстов? Если нет обоснуйте :D, если да то как? как решить проблему с произвольной длинной входа?\n",
        "\n",
        "<Ответ>\n",
        "\n",
        "**Вопрос 6**: Attention - что это такое, где применяют и как? Приведите пример использования на какой-нибудь задаче\n",
        "\n",
        "<Ответ>"
      ]
    },
    {
      "metadata": {
        "id": "2FeHNGMUcWFy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Grading\n",
        "* starting at zero points\n",
        "* +2 for describing your iteration path in a report below (compare models).\n",
        "* +2 for correct check questions\n",
        "* +3 (7 total) for 99% accuracy with simple NMT model on __TEST__ dataset\n",
        "* +3 (10 total) for 99% accuracy with attention NMT model on __TEST__ dataset\n",
        "----\n",
        "* tatoeba bonus for accuracy on __TEST__ dataset:\n",
        "    * +2 for report\n",
        "    * 60% (14 total)\n",
        "    * 65% (16 total)\n",
        "    * 70% (18 total)\n",
        "    * 75% (20 total)\n",
        "    \n",
        "## Bonus points\n",
        "\n",
        "Common ways to get bonus points are:\n",
        "* Get higher score, obviously.\n",
        "* Anything special about your NN. For example \"A super-small/fast NN that gets 99%\" gets a bonus.\n",
        "* Any detailed analysis of the results. (attention maps, whatever)"
      ]
    },
    {
      "metadata": {
        "id": "EqQu8GxccWFz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "VfKkRhBmcWF0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# additional packages for this notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WYJcxJsDcWF4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ! pip install faker tqdm babel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o8NY3MxJcWF7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task - translation\n",
        "\n",
        "The machine translation is old and well-known field in natural language processing. From the 1950s scientists tried to create a model to automatically translate from say French to English. Nowadays it became possible and the attention mechanism takes great part in that. Here the example image with attention map for the neural machine translation of sample phrase:\n",
        "<p align=\"center\">\n",
        "  <img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/12/Screen-Shot-2015-12-30-at-1.23.48-PM.png\" width=\"400\">\n",
        "</p>"
      ]
    },
    {
      "metadata": {
        "id": "4Vwlzg_PcWF8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In our lab we will concentrate on much simplier task: we will translate from human readable date to machine readable one.\n",
        "\n",
        "To do this we need to get one more concept - Sequence-to-Sequence language modeling.\n",
        "The idea of such architecture is here:\n",
        "<p aling=\"center\">\n",
        "<img src=\"./img/simple_nmt.jpg\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "There is an Embeding layer at the bottom, the RNN in the middle and softmax as an output."
      ]
    },
    {
      "metadata": {
        "id": "z9tGNB0m5bq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35bb830f-5037-4e9f-863b-360fe5e1eb5f"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, Bidirectional\n",
        "from keras.layers.core import *\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import *\n",
        "from keras.layers.merge import Multiply\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "import keras.backend as K\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "2vqv2aIFcWGD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "_2zMrKvecWGE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data"
      ]
    },
    {
      "metadata": {
        "id": "DiHiJe835brn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we need to generate data. It will be dates in different text formats and in fixed output format."
      ]
    },
    {
      "metadata": {
        "id": "GYTWkWfdch2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "7e5374d9-edab-4d8a-d11a-9e95e5e29cd6"
      },
      "cell_type": "code",
      "source": [
        "!pip install faker\n",
        "!pip install tqdm\n",
        "!pip install  babel"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting faker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/50/69efd9250a2be64f23ba1985e6b61ab9fcf829d75850044e2a8e4dfb909c/Faker-0.8.15-py2.py3-none-any.whl (741kB)\n",
            "\u001b[K    100% |████████████████████████████████| 747kB 5.4MB/s \n",
            "\u001b[?25hCollecting text-unidecode==1.2 (from faker)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/42/d717cc2b4520fb09e45b344b1b0b4e81aa672001dd128c180fabc655c341/text_unidecode-1.2-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from faker) (1.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.6/dist-packages (from faker) (2.5.3)\n",
            "Installing collected packages: text-unidecode, faker\n",
            "Successfully installed faker-0.8.15 text-unidecode-1.2\n",
            "Collecting tqdm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/ca/6524dfba7a0e850d3fda223693779035ddc8bf5c242acd9ee4eb9e52711a/tqdm-4.23.3-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 2.0MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "Successfully installed tqdm-4.23.3\n",
            "Collecting babel\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/03/14e68ad12e771a79cf96792f7158d68a7b3d8c7b2badf39e9ef1f65b57d6/Babel-2.5.3-py2.py3-none-any.whl (6.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 6.8MB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=0a in /usr/local/lib/python3.6/dist-packages (from babel) (2018.4)\n",
            "Installing collected packages: babel\n",
            "Successfully installed babel-2.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lqr3mM4D5bro",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from babel.dates import format_date\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pi8idIsn5brw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fake = Faker()\n",
        "\n",
        "FORMATS = ['short',\n",
        "           'medium',\n",
        "           'long',\n",
        "           'full',\n",
        "           'd MMM YYY', \n",
        "           'd MMMM YYY',\n",
        "           'dd MMM YYY',\n",
        "           'd MMM, YYY',\n",
        "           'd MMMM, YYY',\n",
        "           'dd, MMM YYY',\n",
        "           'd MM YY',\n",
        "           'd MMMM YYY',\n",
        "           'MMMM d YYY',\n",
        "           'MMMM d, YYY',\n",
        "           'dd.MM.YY']\n",
        "\n",
        "# change this if you want it to work with another language\n",
        "LOCALES = ['en_US']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "67qzEjMm5br1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_date():\n",
        "    \"\"\"\n",
        "        Creates some fake dates \n",
        "        :returns: tuple containing human readable string, machine readable string, and date object\n",
        "    \"\"\"\n",
        "    dt = fake.date_object()\n",
        "\n",
        "    try:\n",
        "        human_readable = format_date(dt, format=random.choice(FORMATS), locale=random.choice(LOCALES))\n",
        "\n",
        "        case_change = random.choice([0,1,2])\n",
        "        if case_change == 1:\n",
        "            human_readable = human_readable.upper()\n",
        "        elif case_change == 2:\n",
        "            human_readable = human_readable.lower()\n",
        "        # if case_change == 0, do nothing\n",
        "\n",
        "        machine_readable = dt.isoformat()\n",
        "    except AttributeError as e:\n",
        "        return None, None, None\n",
        "\n",
        "    return human_readable, machine_readable, dt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j9eTZ13P5br6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_dataset(n_examples):\n",
        "    \"\"\"\n",
        "        Creates a dataset with n_examples and vocabularies\n",
        "        :n_examples: the number of examples to generate\n",
        "    \"\"\"\n",
        "    human_vocab = set()\n",
        "    machine_vocab = set()\n",
        "    dataset = []\n",
        "\n",
        "    for i in tqdm(range(n_examples)):\n",
        "        h, m, _ = create_date()\n",
        "        if h is not None:\n",
        "            dataset.append((h, m))\n",
        "            human_vocab.update(tuple(h))\n",
        "            machine_vocab.update(tuple(m))\n",
        "\n",
        "    human = dict(zip(list(human_vocab) + ['<unk>', '<pad>'], \n",
        "                     list(range(len(human_vocab) + 2))))\n",
        "    inv_machine = dict(enumerate(list(machine_vocab) + ['<unk>', '<pad>']))\n",
        "    machine = {v:k for k,v in inv_machine.items()}\n",
        " \n",
        "    return dataset, human, machine, inv_machine"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EsQHOc3D5br9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def string_to_int(string, lenght, vocab):\n",
        "    if len(string) > lenght:\n",
        "        string = string[:lenght]\n",
        "        \n",
        "    rep = list(map(lambda x: vocab.get(x, '<unk>'), string))\n",
        "    \n",
        "    if len(string) < lenght:\n",
        "        rep += [vocab['<pad>']] * (lenght - len(string))\n",
        "    \n",
        "    return rep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MYU62jZi5bsB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def int_to_string(ints, inv_vocab):\n",
        "    return [inv_vocab[i] for i in ints]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yTghggDB5bsE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Actually generating data:"
      ]
    },
    {
      "metadata": {
        "id": "As0XeIDa5bsF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "682c97df-5ece-4601-b160-3102703dff3c"
      },
      "cell_type": "code",
      "source": [
        "fake.seed(42)\n",
        "random.seed(42)\n",
        "N = int(3e5)\n",
        "dataset, human_vocab, machine_vocab, inv_machine_vocab = create_dataset(N)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 300000/300000 [00:18<00:00, 15990.57it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "qwN8hGFn23Pt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e233919-72c2-45f5-a580-206e1a98c9e9"
      },
      "cell_type": "code",
      "source": [
        "dataset[2]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tuesday, september 14, 1971', '1971-09-14')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "ITej2gDY5bsN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TIME_STEPS = 20 # change me if u want\n",
        "\n",
        "inputs, targets = zip(*dataset)\n",
        "inputs = np.array([string_to_int(i, TIME_STEPS, human_vocab) for i in inputs])\n",
        "targets = [string_to_int(t, TIME_STEPS, machine_vocab) for t in targets]\n",
        "targets = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), targets)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_zp8STYHcWGq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_valid, y_valid, X_test, y_test = (\n",
        "    inputs[:int(2e5)], targets[:int(2e5)], \n",
        "    inputs[int(2e5):-int(5e4)], targets[int(2e5):-int(5e4)],  \n",
        "    inputs[-int(5e4):], targets[-int(5e4):], )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yxtlwp8hcWGt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "r7oXde9ocWGt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Part 1: Simple NMT"
      ]
    },
    {
      "metadata": {
        "id": "qWo4x0DM5brd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# :good-enouht:\n",
        "ENCODER_UNITS = 64 # change me if u want\n",
        "DECODER_UNITS = 32 # change me if u want"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QQD_Dy8_0MSx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input - [bs; in_time_len]\n",
        "# output - [bs; out_time_len]; out_time_len=10\n",
        "\n",
        "def model_simple_nmt(in_chars, out_chars):\n",
        "    # RNN encoder -> hidden representation -> RNN decoder\n",
        "    inputs = Input(shape=(TIME_STEPS,))\n",
        "    \n",
        "    # your code\n",
        "    \n",
        "    x = Embedding(input_dim=in_chars, output_dim=ENCODER_UNITS, input_length=TIME_STEPS)(inputs)\n",
        "    x = Bidirectional(LSTM(DECODER_UNITS, return_sequences=True))(x)\n",
        "    x = Dense(out_chars)(x)\n",
        "    output = Activation(\"softmax\")(x)\n",
        "    \n",
        "    model = Model(input=[inputs], output=output)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ztwvgRe35bsJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "79c149f7-8218-4f23-c621-a7a9eab987e4"
      },
      "cell_type": "code",
      "source": [
        "m = model_simple_nmt(len(human_vocab), len(machine_vocab))\n",
        "\n",
        "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(m.summary())"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_10 (Embedding)     (None, 20, 32)            1920      \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 20, 64)            16640     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 20, 13)            845       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 20, 13)            0         \n",
            "=================================================================\n",
            "Total params: 19,405\n",
            "Trainable params: 19,405\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ac...)`\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "l_wPSU2t5bsP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "82ca89ff-7989-4edd-ac32-781864f0f05b"
      },
      "cell_type": "code",
      "source": [
        "m.fit(\n",
        "    [X_train], y_train, \n",
        "    validation_data=(X_valid, y_valid),\n",
        "    epochs=1, batch_size=64, \n",
        "    validation_split=0.1)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 200000 samples, validate on 50000 samples\n",
            "Epoch 1/1\n",
            " 43200/200000 [=====>........................] - ETA: 4:41 - loss: 0.0303 - acc: 0.9901"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "199936/200000 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9875"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r200000/200000 [==============================] - 380s 2ms/step - loss: 0.0480 - acc: 0.9875 - val_loss: 0.0275 - val_acc: 0.9908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff79a575390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "oAs7pIYZcWG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2e367c8f-91dd-4494-842a-8f01d6d46ba8"
      },
      "cell_type": "code",
      "source": [
        "m.evaluate([X_test], y_test)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 49s 980us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.027106830201148988, 0.9909010007095337]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "fwYByTjJ5bsS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets check our model:"
      ]
    },
    {
      "metadata": {
        "id": "EIMBnjqY5bsS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EXAMPLES = ['3 May 1979', '5 Apr 09', '20th February 2016', 'Wed 10 Jul 2007']\n",
        "\n",
        "def run_example(model, input_vocabulary, inv_output_vocabulary, text):\n",
        "    encoded = string_to_int(text, TIME_STEPS, input_vocabulary)\n",
        "    prediction = model.predict(np.array([encoded]))\n",
        "    prediction = np.argmax(prediction[0], axis=-1)\n",
        "    return int_to_string(prediction, inv_output_vocabulary)\n",
        "\n",
        "def run_examples(model, input_vocabulary, inv_output_vocabulary, examples=EXAMPLES):\n",
        "    predicted = []\n",
        "    for example in examples:\n",
        "        predicted.append(''.join(run_example(model, input_vocabulary, inv_output_vocabulary, example)))\n",
        "        print('input:', example)\n",
        "        print('output:', predicted[-1])\n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0cSByOaY5bsW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "f7e37744-2026-4914-f8e7-5db05cf0b903"
      },
      "cell_type": "code",
      "source": [
        "run_examples(m, human_vocab, inv_machine_vocab)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input: 3 May 1979\n",
            "output: 1979-05-03<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "input: 5 Apr 09\n",
            "output: 2009-04-05<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "input: 20th February 2016\n",
            "output: 2016-02-00<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "input: Wed 10 Jul 2007\n",
            "output: 2000-03-00<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1979-05-03<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
              " '2009-04-05<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
              " '2016-02-00<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
              " '2000-03-00<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "wYeWMC8jxJLy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "5BgYfPlMcWHI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Part 2: All u need is attention"
      ]
    },
    {
      "metadata": {
        "id": "-zDW4e6j5brg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we use more complex idea that simple seq2seq: we're adding two explicit parts of our network - encoder and decoder (which is applied attention on). The explanatory picture for this idea is below:\n",
        "<p aling=\"center\"><img src=\"https://i.stack.imgur.com/Zwsmz.png\"></p>\n",
        "\n",
        "The lower part of the network is encoding the input to some hidden intermediate representation and the upper part is decoing the hidвen represenataion into some readable output."
      ]
    },
    {
      "metadata": {
        "id": "TS2BOYfVcWHK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# :good-enouht:\n",
        "ENCODER_UNITS = 32 # change me if u want\n",
        "DECODER_UNITS = 32 # change me if u want\n",
        "TIME_STEPS = 20 # change me if u want"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w0J4xK0Xdyhm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_attention_nmt(in_chars, out_chars):\n",
        "    inputs = Input(shape=(TIME_STEPS,))\n",
        "    x = Embedding(input_dim=in_chars, output_dim=ENCODER_UNITS, input_length=TIME_STEPS)(inputs)\n",
        "    _, state_h, state_c = LSTM(32, return_state=True)(x)\n",
        "    encoder_states = [state_h, state_c]\n",
        "    \n",
        "    attention = Dense(20, activation='softmax')(state_h)\n",
        "    attention = RepeatVector(TIME_STEPS)(attention)\n",
        "    \n",
        "    x = LSTM(32, return_sequences=True)(attention, initial_state=encoder_states)\n",
        "    output = Dense(out_chars, activation='softmax')(x)\n",
        "\n",
        "    model = Model([inputs], output)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HzGZjnfqd4V_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "857d150e-c53c-492e-f2cf-97a8e62824af"
      },
      "cell_type": "code",
      "source": [
        "m = model_attention_nmt(len(human_vocab), len(machine_vocab))\n",
        "\n",
        "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(m.summary())"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 20, 32)       1920        input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_9 (LSTM)                   [(None, 32), (None,  8320        embedding_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 20)           660         lstm_9[0][1]                     \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_2 (RepeatVector)  (None, 20, 20)       0           dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_10 (LSTM)                  (None, 20, 32)       6784        repeat_vector_2[0][0]            \n",
            "                                                                 lstm_9[0][1]                     \n",
            "                                                                 lstm_9[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 20, 13)       429         lstm_10[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 18,113\n",
            "Trainable params: 18,113\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gd7zJCLRd-qE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1386
        },
        "outputId": "2cbf2205-d868-43a0-b966-78bf3c0cb07e"
      },
      "cell_type": "code",
      "source": [
        "m.fit(\n",
        "    [X_train], y_train, \n",
        "    validation_data=(X_valid, y_valid),\n",
        "    epochs=4, batch_size=64, \n",
        "    validation_split=0.1)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 200000 samples, validate on 50000 samples\n",
            "Epoch 1/4\n",
            " 43200/200000 [=====>........................] - ETA: 4:40 - loss: 0.8957 - acc: 0.7089"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "118784/200000 [================>.............] - ETA: 2:22 - loss: 0.5946 - acc: 0.7981"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-cc75ee02ad99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     validation_split=0.1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DBDoMAdzcWHa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m.evaluate([X_test], y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "apFSyBptcWHe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Report\n",
        "\n",
        "* final architectures\n",
        "* comparison\n",
        "* as well as training method and tricks\n"
      ]
    },
    {
      "metadata": {
        "id": "oLQEAqs_cWHf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "FJ3n8nQdcWHf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 3*: tatoeba - real NMT"
      ]
    },
    {
      "metadata": {
        "id": "hwljf0tPcWHi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data"
      ]
    },
    {
      "metadata": {
        "id": "_UyNaUZHcWHj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dataset from http://www.manythings.org/anki/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xLuwrHGLcWHq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "4c8d4327-74a7-4df1-d800-e5212cd3145a"
      },
      "cell_type": "code",
      "source": [
        "! wget http://www.manythings.org/anki/rus-eng.zip"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-05-08 20:18:38--  http://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2400:cb00:2048:1::6818:6cc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6366669 (6.1M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip’\n",
            "\n",
            "rus-eng.zip         100%[===================>]   6.07M  13.4MB/s    in 0.5s    \n",
            "\n",
            "2018-05-08 20:18:38 (13.4 MB/s) - ‘rus-eng.zip’ saved [6366669/6366669]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mnu-E0JecWHw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "eafc6d33-5496-4fc6-8e7c-5f09ea16b45f"
      },
      "cell_type": "code",
      "source": [
        "! unzip ./rus-eng.zip"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GshYJ5kLcWHz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(\"./rus.txt\") as fin:\n",
        "    data = fin.readlines()\n",
        "data = list(map(lambda x: x.replace(\"\\n\", \"\").lower(), data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mpv2E6BccWH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f96c665-80e2-4708-f906-1e10cbc673ec"
      },
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300108"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "y3U_GW9pcWH4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = data[:int(1e5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hKS5DgzgcWH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1eae8523-6a4e-4bf0-8b09-4f2e0b0678e9"
      },
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "VRCtWijBcWH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3513be4d-692e-4cb0-cd8b-b3f4f135d5d9"
      },
      "cell_type": "code",
      "source": [
        "data[-1]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tom is here to see you.\\tк тебе том пришёл.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "dTRFqbf4cWIC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "----"
      ]
    },
    {
      "metadata": {
        "id": "trCrrKj8cWIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "source = list(map(lambda x: x.split(\"\\t\")[0], data))\n",
        "target = list(map(lambda x: x.split(\"\\t\")[1], data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sx37NXvKcWII",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "source_vocab = set(\"\".join(source).strip())\n",
        "target_vocab = set(\"\".join(target).strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QMzyvv1lcWIN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "source_vocab = dict(zip(\n",
        "    list(source_vocab) + ['<unk>', '<pad>'], \n",
        "    list(range(len(source_vocab) + 2))))\n",
        "target_vocab = dict(zip(\n",
        "    list(target_vocab) + ['<unk>', '<pad>'], \n",
        "    list(range(len(target_vocab) + 2))))\n",
        "inv_target_vocab = dict(enumerate(list(target_vocab) + ['<unk>', '<pad>']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YiaF7rMBcWIR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TIME_STEPS = 32\n",
        "ENCODER_UNITS = 256\n",
        "DECODER_UNITS = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sA6hKzp_cWIW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_attention_nmt(in_chars, out_chars):\n",
        "    inputs = Input(shape=(TIME_STEPS,))\n",
        "    \n",
        "    x = Embedding(input_dim=in_chars, output_dim=ENCODER_UNITS, input_length=TIME_STEPS)(inputs)\n",
        "    x = Bidirectional(LSTM(DECODER_UNITS, return_sequences=True))(x)\n",
        "    x = Dense(out_chars)(x)\n",
        "    output = Activation(\"softmax\")(x)\n",
        "    \n",
        "    model = Model(input=[inputs], output=output)\n",
        "\n",
        "    model = Model(input=[inputs], output=output)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oXaQws1ecWIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "60ae1ea7-160e-44bf-c788-f3d9e63fb72e"
      },
      "cell_type": "code",
      "source": [
        "m = model_attention_nmt(len(source_vocab), len(target_vocab))\n",
        "\n",
        "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(m.summary())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 32, 256)           13824     \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 32, 512)           1050624   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32, 87)            44631     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 32, 87)            0         \n",
            "=================================================================\n",
            "Total params: 1,109,079\n",
            "Trainable params: 1,109,079\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ac...)`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"ac...)`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-QOhGmbscWId",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputs = np.array([string_to_int(i, TIME_STEPS, source_vocab) for i in source])\n",
        "targets = [string_to_int(t, TIME_STEPS, target_vocab) for t in target]\n",
        "targets = np.array(list(map(lambda x: to_categorical(x, num_classes=len(target_vocab)), targets)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jFObXhtRcWIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "692283c5-d267-4465-d427-32e4915bdd20"
      },
      "cell_type": "code",
      "source": [
        "m.fit(\n",
        "    [inputs], targets, \n",
        "    epochs=1, batch_size=64, \n",
        "    validation_split=0.1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 90000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "44096/90000 [=============>................] - ETA: 1:57 - loss: 1.8997 - acc: 0.5126"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 238s 3ms/step - loss: 1.8551 - acc: 0.5213 - val_loss: 2.2093 - val_acc: 0.4200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1968e6fa20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "nRCwIFUKcWIh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "outputId": "80f51c33-35af-4f95-bfb6-dd56922ad282"
      },
      "cell_type": "code",
      "source": [
        "run_example(m, source_vocab, inv_target_vocab, 'go')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['о',\n",
              " 'а',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "aPwJM8hPcWIk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tatoeba Report\n",
        "\n",
        "* final architectures\n",
        "* comparison\n",
        "* as well as training method and tricks\n"
      ]
    },
    {
      "metadata": {
        "id": "708MerkrcWIl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}