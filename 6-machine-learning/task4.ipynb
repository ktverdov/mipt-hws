{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#удаляем служебные колонки, признак pdb_chain - строка, его хэшируем\n",
    "def preprocess_data(df):\n",
    "    for column in ['DSSR', 'Id', 'index']:\n",
    "        if column in df.columns:\n",
    "            df.drop(column, axis=1, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    df['pdb_chain'] = df['pdb_chain'].apply(hash)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_table('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocess_data(df_train)\n",
    "X_train = df_train.loc[:, df_train.columns != 'mg']\n",
    "Y_train = df_train['mg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#снижаем размерность признаков, на самом деле можно было и побольше удалить\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "selector_f = SelectPercentile(f_classif, percentile=70)\n",
    "X_train = selector_f.fit_transform(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#фиксируем learning rate и подбираем под него число деревьев\n",
    "\n",
    "#scale_pos_weight = 6, т.к. учебная выборка была несбалансированна \n",
    "#(кол-во случаев, когда Mg не присоединился) / (кол-во случаев когда присоединился) ~ 6\n",
    "\n",
    "#для остальных параметров выбраны более менее стандартные значения\n",
    "\n",
    "clf = XGBClassifier(learning_rate=0.2, n_estimators=4000, max_depth=6, min_child_weight=1, \n",
    "                    subsample=0.8, colsample_bytree=0.7, scale_pos_weight=6, objective= 'binary:logistic',\n",
    "                    nthread=8)\n",
    "\n",
    "cvresult = xgb.cv(clf.get_xgb_params(), xgb.DMatrix(X_train, label=Y_train), \n",
    "                  num_boost_round=clf.get_params()['n_estimators'], nfold=5, early_stopping_rounds=50)\n",
    "\n",
    "#в cv_result получили n_estimator ~ 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.7, gamma=0, learning_rate=0.2, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=3000,\n",
       "       n_jobs=1, nthread=8, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=6, seed=None,\n",
       "       silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier(learning_rate=0.2, n_estimators=3000, max_depth=6, min_child_weight=1, \n",
    "                    subsample=0.8, colsample_bytree=0.7, scale_pos_weight=6, objective= 'binary:logistic',\n",
    "                    nthread=8)\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_train = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9751276277566736\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(Y_train, Y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.7, gamma=0, learning_rate=0.2, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=3000,\n",
       "       n_jobs=1, nthread=8, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=6, seed=None,\n",
       "       silent=True, subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=8,\n",
       "       param_grid={'max_depth': [4, 5, 6, 7, 8]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(f1_score), verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#зафиксировав learning_rate и подходящее число деревьев ищем глубину\n",
    "\n",
    "param_test1 = {'max_depth': [4, 5, 6, 7, 8]}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.2, n_estimators=3000, max_depth=6, min_child_weight=1, \n",
    "                                                    subsample=0.8, colsample_bytree=0.7, scale_pos_weight=6, gamma=0, \n",
    "                                                      objective= 'binary:logistic', nthread=8),\n",
    "                        param_grid = param_test1, scoring=make_scorer(f1_score), iid=False, cv=5, n_jobs=8)\n",
    "gsearch1.fit(X_train, Y_train)\n",
    "\n",
    "#совсем не угадал с range и все считал зря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: 0.20397, std: 0.03689, params: {'max_depth': 4}, mean: 0.16909, std: 0.04657, params: {'max_depth': 5}, mean: 0.14382, std: 0.05216, params: {'max_depth': 6}, mean: 0.13017, std: 0.06159, params: {'max_depth': 7}, mean: 0.12099, std: 0.06833, params: {'max_depth': 8}]\n",
      "{'max_depth': 4}\n",
      "0.20396999262039933\n"
     ]
    }
   ],
   "source": [
    "print(gsearch1.grid_scores_)\n",
    "print(gsearch1.best_params_)\n",
    "print(gsearch1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.7, gamma=0, learning_rate=0.2, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=3000,\n",
       "       n_jobs=1, nthread=8, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=6, seed=None,\n",
       "       silent=True, subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=8, param_grid={'max_depth': [3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(f1_score), verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {'max_depth': [3]}\n",
    "\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.2, n_estimators=3000, max_depth=6, min_child_weight=1, \n",
    "                                                    subsample=0.8, colsample_bytree=0.7, scale_pos_weight=6, gamma=0, \n",
    "                                                      objective= 'binary:logistic', nthread=8),\n",
    "                        param_grid = param_test2, scoring=make_scorer(f1_score), iid=False, cv=5, n_jobs=8)\n",
    "gsearch2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: 0.23463, std: 0.03032, params: {'max_depth': 3}]\n",
      "{'max_depth': 3}\n",
      "0.23463357039832702\n"
     ]
    }
   ],
   "source": [
    "print(gsearch2.grid_scores_)\n",
    "print(gsearch2.best_params_)\n",
    "print(gsearch2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.7, gamma=0, learning_rate=0.2, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=3000,\n",
       "       n_jobs=1, nthread=8, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=6, seed=None,\n",
       "       silent=True, subsample=0.8),\n",
       "       fit_params=None, iid=False, n_jobs=8, param_grid={'max_depth': [3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(f1_score), verbose=0)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {'max_depth': [2]}\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.2, n_estimators=3000, max_depth=6, min_child_weight=1, \n",
    "                                                    subsample=0.8, colsample_bytree=0.7, scale_pos_weight=6, gamma=0, \n",
    "                                                      objective= 'binary:logistic', nthread=8),\n",
    "                        param_grid = param_test2, scoring=make_scorer(f1_score), iid=False, cv=5, n_jobs=8)\n",
    "gsearch3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: 0.23463, std: 0.03032, params: {'max_depth': 3}]\n",
      "{'max_depth': 3}\n",
      "0.23463357039832702\n"
     ]
    }
   ],
   "source": [
    "print(gsearch3.grid_scores_)\n",
    "print(gsearch3.best_params_)\n",
    "print(gsearch3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Последние два результата странные, была выбрана глубина 3, т.к. 2 как-то слишком мало"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.7, gamma=1, learning_rate=0.2, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=3000,\n",
       "       n_jobs=1, nthread=8, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=6, seed=None,\n",
       "       silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = XGBClassifier(learning_rate=0.2, n_estimators=3000, max_depth=3, min_child_weight=1, \n",
    "                    subsample=0.8, colsample_bytree=0.7, scale_pos_weight=6, objective= 'binary:logistic',\n",
    "                    nthread=8, gamma=1)\n",
    "clf1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./test.csv')\n",
    "df_test = preprocess_data(df_test)\n",
    "df_test = selector_f.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = clf1.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame({\"Id\" : range(len(Y_pred)), \"mg\" : Y_pred})\n",
    "df_out.to_csv(\"sample_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск с вышеприведнными параметрами получил результат $0.37891$ на PublicLeaderboard и шаги по дальнейшему улучшению не предпринимались.\n",
    "\n",
    "Что предполаголось делать: таким же образом потюнить min_child_weight, gammа (была посылка с gamma=1, но она ухудшила score),  subsample and colsample_bytree. Уменьшить learning_rate и подобрать к нему еще раз кол-во деревьев. Не выкидывать все строки с Nan, а выкинуть ненужные столбцы, в остальных заменить средним / ... .\n",
    "\n",
    "Почему этого не было: все достаточно долго считается, даже на google.cloud. Признаков так много, что не очень понятно, что с ними делать: ручками их как-то долго перебирать и графики смотреть. Возможно данных слишком много для первого учебного kaggle?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
